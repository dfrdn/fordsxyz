---
title: 'A Game of Torts'
subtitle: 'Comparing Tort Liability Regimes Using Game Theory in the Context of Autonomous Vehicles'
description: >
  When there is a vehicular accident, the driver, if there is fault or negligence on his part, is obliged to pay for the damages caused by his or her act or omission.  What if there is no driver, who pays?

  This Paper attempts to compare different tort liability regimes as applied in the case of accidents involving Level 5 autonomous vehicles by determining how they affect the behaviors of different actors in society such as car-owners, manufacturers, or pedestrians by using game theory. Such predicted behaviors will then be tested against the underlying values and purposes of tort law.
author:
tags: []
---

## Introduction

> If something can go wrong, it will.  
> — Murphy's Law

When there is a vehicular accident, the driver, if there is fault or negligence on his part, is obliged to pay for the damages caused by his or her act or omission.[^1] What if there is no driver, who pays?

<v-img src='electric_car.svg' alt='car'></v-img>

On 7 May 2016, Joshua Brown died when the autopilot sensors of his Tesla Model S failed to detect a white tractor-trailer and crashed full speed under the said truck.[^2] This was the first known death caused by a self-driving car.[^3] According to the National Transportation Safety Board (NTSB), part of the probable cause of the crash was the driver’s inattentiveness due to his over-reliance on the autopilot mechanism of the car.[^4] As a result, the NTSB said that the car manufacturer, Tesla, is not at fault[^5] in line with the finding of the National Highway Traffic Safety Administration (NHTSA) which found no defect in the self-driving system of Tesla.[^6] However, the reason for this is because the Tesla self-driving car is only a level 2 system[^7] wherein the driver’s engagement during the operation is still necessary.[^8] Once a car reaches Level 3 automation, “the responsibility for monitoring the driving environment shifts from the driver to the system.”[^9]

In that case, a difficulty arises in finding who should be liable in case there is an accident as the driver is no longer the one primarily responsible for the safety of his journey. The problem becomes more apparent in cases of Level 5 autonomous vehicles,[^10] or fully autonomous cars requiring no human intervention. Once the roads are filled with fully autonomous cars, who would be held liable if there is an accident? In other words, who will be at fault if a vehicle gets into an accident when there is no more human driver because only the computer artificial intelligence (AI) is in control?[^11] While autonomous vehicles may be safer,[^12] the question of liability cannot be neglected as accidents are inevitable. In the words of Vladeck, “\[n\]o matter how well-designed and programmed self-driving cars are, factors beyond the machine’s control virtually guarantee that at some point the car will have an accident that will cause injury of some kind, and will act in ways that are not necessarily ordained by their programming.”[^13]

The law on torts governs such circumstance. There is difficulty because the principles of reasonability, foreseeability, and causation are the primary bases for liability in the law on torts.[^14] Given the autonomous and unpredictable nature of AI systems, it is unclear how these principles apply.[^15] Can there be such a thing as a reasonable AI? If so, by what standard? If we cannot determine the reasonability of an AI’s action, how can we ascertain the foreseeability of an accident? Who or what will be considered as the proximate cause of the accident? These questions all lead to the main question of, “who pays?”

There are several liability regimes under the law on torts which may be used in determining “who pays” such as strict liability, vicarious liability, and comparative negligence. These different regimes affect the behavior of the people in different ways. Still, they all point to the primary tort law goal of preventing accidents and minimizing losses.[^16] Law is a mode of regulating people[^17] in order to achieve social order.[^18] The specific social order sought by the law on torts is the protection of people from injuries caused by other members of society, whether through willful intent or through negligence.[^19] This objective is done through the imposition of liability for whoever causes injury by breaching the mutual duties imposed by the society, as measured by the legal rights of each member of society.[^20] Such imposition of liability “substantially affects how categories of actors respond to the risks they create or confront.”[^21] Thus, different liability regimes lead to different behaviors. For instance, if no liability is imposed on motorists when they injure pedestrians, then there would be no incentive for them to exercise due care leading to the inference that they would not exercise due care thereby increasing the number of accidents.[^22]

This Paper will attempt to compare different liability regimes as applied in the case of accidents involving autonomous vehicles by determining how they might affect the behaviors of different actors in society such as motorists, manufacturers, or pedestrians by using game theory. Game theory is defined as “a set of tools and a language for describing and predicting strategic behavior.”[^23] Strategic behavior arises when there are at least two interacting actors and their decisions depend on the expectation of each actor of what the others will do.[^24] This means that “our behavioral decisions are intertwined”[^25] and such fact must be taken into account in predicting outcomes and in regulating behaviors such as in a legal system.[^26] Thus, game theory may be able to provide assistance in determining “who pays” by providing insights as to how different liability regimes may affect the way people will behave.[^27] Such predicted behaviors will then be juxtaposed with the underlying values and objectives of tort law.

## Torts

### Definition

The word “tort” is a French term which originated from the Latin word _torquere_ which means “to twist.”[^28] This is because a tortious conduct is a conduct that is considered twisted or crooked.[^29] It is an “unlawful violation of private right, not created by contract, and which gives rise to an action for damages.”[^30] It is also defined as “an act or omission producing an injury to another, without any previous existing lawful relation of which the said act or omission may be said to be a natural outgrowth or incident.”[^31] Thus, the basic elements of a tort are:

1. Damages suffered by the plaintiff;
2. Fault or negligence of the defendant, or some other person for whose acts he must respond; and
3. Connection of cause and effect between the fault or negligence of the defendant and the damages incurred by the plaintiff.[^32]

Thus, tort law deals with situations where a person injures another person by breaching his legal duty not to violate the right of another member of society.[^33] Consequently, it is the law governing cases of vehicular accidents. In determining “who pays,” it is thus necessary to look into the underlying values of tort law and its purposes.

### Purpose

Tort law contributes to the objective of the law to reduce, or if possible, to eliminate risks in society by providing deterrence to harmful activities.[^34] However, since it is impossible to totally eliminate injuries because “men voluntarily accepts risks as a quid pro quo for their needs,” tort law provides the alternative of providing redress to anyone injured,[^35] _i.e._, allocating risks and liabilities in the society.[^36] Jurists are in agreement that the central aim of tort law is the reduction of accidents.[^37] In line with this, the major purposes of tort law are: “1) to provide a peaceful means for adjusting the rights of parties who might otherwise take the law into their own hands; 2) deter wrongful conduct; 3) to encourage socially responsible behavior; and 4) to restore injured parties to their original condition, insofar as the law can do this, by compensating them for their injury.”[^38]

In addition, tort law also aims to balance conflicting interests.[^39] As Dean Wright explained, doing all the things that constitute modern living necessarily leads to some losses or injuries.[^40] Thus, according to her,

> \[t\]he purpose of the law of torts is to adjust these losses and to afford compensation for injuries sustained by one person as the result of the conduct of another…The study of the law of torts is, therefore, a study of the extent which the law will shift losses sustained in modern society from the person affected to the shoulder of him who caused the loss or more.[^41]

### Theoretical Justification

There are two main theoretical perspectives justifying tort law and the shifting of losses — the moral and social perspective.[^42]

Under the moral perspective, liability may be imposed on a tort because such act or omission is considered a moral wrong.[^43] This perspective is in line with the maxim _Ubi jus ibi remedium_ — there is no wrong without a remedy.[^44] It may be said that the liability imposed by tort law is deemed as a private penalty for the wrong done because of one’s moral shortcoming.[^45] As such, if no wrong is done, there should be no basis to impose liability under this perspective.

The social perspective justifies the imposition of liability for tortious conduct “because of the good that it will do to the society as a whole and its function of encouraging socially responsible behavior.”[^46] This perspective is in line with the idea that law is a mode of regulating behavior. It is also reflected in the purpose of tort law of balancing conflicting interests.[^47] From this perspective, the imposition of liability encourages certain behaviors which contribute to the social order and deters others which may be detrimental to the social order.

A slight variation of the social perspective is the economic perspective which views tort law as a system of allocating risks in order to maximize wealth and minimize costs.[^48] The statement of the Court in _Phoenix v. IAC_[^49] that “\[o\]ur law on quasi-delicts seeks to reduce the risks and burdens of living in society and to allocate them among the members of society”[^50] is reflective of the economic perspective.[^51] The economic perspective may also be used to justify liabilities not arising from fault or negligence, _i.e._, strict liability torts.

### Classifications

In order to cover the wide spectrum of injuries and accidents, tort liabilities are classified into three: intentional torts, negligence, and strict liability.[^52] Intentional torts are those wherein the injury caused is actually intended by the person who caused the injury.[^53] In contrast, negligence torts are committed when one fails to do an act or omission with due care and causes foreseeable harm to another.[^54] Lastly, strict liability torts are those wherein one may be held liable regardless of the existence of fault or negligence on his part.[^55]

These classifications translate to different liability regimes which may be used in allocating liabilities in accidents involving autonomous vehicles. This paper will limit itself to the following liability regimes: strict liability, strict liability with the defense of contributory negligence, and no liability.

To understand how autonomous vehicles may disrupt tort principles, an inquiry into AI systems and autonomous cars is in order.

## Autonomous Vehicles

### Brief History

Throughout history, humans have been continuously aspiring to make life easier and better. One way of achieving such aspiration is to make artificial creatures capable of doing our tasks for us. We call these creatures robots.

In the year 1961 robots were first employed in the automobile industry. The UNIMATE robot was used by General Motors in manufacturing cars to perform spot welding and to extract die-castings. Soon after, they looked beyond creating more cars using robots but to create cars that are robots — fully autonomous cars. However, mass adoption of robotic technology only began in the early 1980s when Japanese car industry began to use robots on a large scale in their factories thereby decreasing costs and increasing the quality of their products. Eventually, the industrial robot industry became dominated by car manufacturers. It is therefore natural that several states, organizations, and private companies began to seriously pursue the project of creating autonomous cars, or unmanned ground vehicles (UGV) as they called it.

In 1987—1995, the European Commission funded the Eureka Prometheus Project (Programme for a European Traffic of Highest Efficiency and Unprecedented Safety) to research on driverless cars. In the late 1990s, the Defense Advanced Research Projects Agency (DARPA) was authorized “to organize a series of prize competitions for driverless cars in order to develop the military sector of UGVs and make one-third of ground military forces autonomous by 2015.” In the first race of the DARPA Grand Challenge competition on 13 March 2004, none of the cars was able to complete the race. After a year and a half, five vehicles were able to finish the second race. On 3 November 2007, Carnegie Mellon won the third DARPA race at a speed of 22.53 kph. Fast forward to the present, autonomous cars no longer just run in DARPA races at 22.53 kph. Cars capable of partial or conditional automation are now available for the public. We are now closer than ever in achieving the goal of turning our cars into robots.

### Levels of Automation

Cars may be classified into six categories depending on the level of automation: 1) Level 0 — No Automation; 2) Level 1 — Driver Assistance; 3) Level 2 — Partial Automation; 4) Level 3 — Conditional Automation; 5) Level 4 — High Automation; 6) Level 5 — Full Automation.

Level 0 cars are the traditional cars we have where there is totally no automation. Level 1 systems have driver assistance wherein, under certain conditions, the car can control either the steering or the speed but not both at the same time. An example of a level 1 system is an adaptive cruise control. Level 2 systems offer partial automation wherein the car is capable of steering, accelerating, and breaking in certain circumstances. In level 2 systems, the responsibility for monitoring hazards still primarily belong to the human driver. Level 2 systems are pretty common now such as Tesla autopilot, Audi Traffic Jam Assist, and Mercedes-Benz Driver Assistance Systems.

The shift from Level 2 to Level 3 is pivotal as the responsibility for monitoring the driving environment now belongs to the system rather than the human driver. In Level 3 systems, the car can manage most aspects of driving and only prompts the driver to intervene in instances it cannot handle. Thus, the driver must still be available to take over the car at any time. Upon reaching level 4 automation, human oversight or input is no longer necessary under certain conditions such as when driving in a highway. Take note that the availability of the human driver to take over at any time is no longer necessary. Thus, under certain conditions, the computer system is fully in control of the vehicle. In Level 5 systems, the car achieves full automation. This is like Level 4 systems but there is no longer any condition. As such, the car has the capability to drive and control itself under any condition. Consequently, the involvement of the human driver is limited to entering his destination. There are currently no Level 5 systems yet, but some companies are already working towards developing one such as Waymo, which recently has been testing Level 4 autonomous vehicles in Arizona.

This Paper limits itself to accidents involving Level 5 autonomous cars where there really is no more human driver, and everyone can ride as a passenger. Further, it does not aim to deal with cases wherein there is negligence on the part of either the manufacturer, designer, suppliers, or the owner. As such, situations such as when the manufacturer fails to follow certain regulations or when there is an obvious bug in the software system are not covered in this Paper as they may be adequately handled by the current tort law principles such as strict liability for defective products or even liability due to negligence in accordance with the doctrine of res ipsa loquitur. Likewise, instances where the accident is due to the negligence of the owner in the maintenance of his autonomous vehicle is out of the scope of this Paper as such is sufficiently addressed by the rules on negligence and foreseeability.

Thus, the circumstance being contemplated in this paper is when the accident was due to the autonomous car’s own decision. Since we do not know how AI systems really “think,” or how they arrive at a particular decision, such a situation is problematic under the traditional paradigm of tort law imposing liability on who is at fault or at least who is presumed to be at fault. Thus, “for the first time ever, legal systems will hold humans responsible for what an artificial state-transition system ‘decides’ to do.”

Since it is difficult to apply the traditional principles of tort law in determining “who pays,” this Paper will instead study the behavior being encouraged or deterred by different liability regimes and compare those behavior to that sought to be achieved by tort law. Rather than ask the question of “why we should choose this liability regime,” this paper will instead ask “what happens if we choose this liability regime.” This is where game theory comes in.
